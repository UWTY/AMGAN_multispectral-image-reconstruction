{"cells":[{"cell_type":"markdown","metadata":{"id":"8PCMIZ5MuHMP"},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jVhsSCSuJvX"},"outputs":[],"source":["!pip install kornia\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/gdrive')\n","\n","import os\n","import sys\n","import argparse\n","import time\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","import json\n","import kornia\n","from kornia.morphology import erosion\n","\n","# Replace with the actual path to the directory containing model2.py\n","model_dir_in_drive = '/content/gdrive/MyDrive/ColabModel/'\n","# Add the directory to the Python path\n","if model_dir_in_drive not in sys.path:\n","    sys.path.append(model_dir_in_drive)\n","    print(f\"Added {model_dir_in_drive} to sys.path\")\n","else:\n","    print(f\"{model_dir_in_drive} already in sys.path\")\n","\n","from MultimodalUnetGAN import UnetGAN\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","from tqdm import tqdm\n","from scipy.ndimage import binary_erosion\n","from skimage.metrics import structural_similarity as ssim\n","\n","import importlib\n","\n","# GPU optimization\n","if torch.cuda.is_available():\n","    torch.backends.cudnn.benchmark = True\n"]},{"cell_type":"markdown","metadata":{"id":"F0vC7NRmNpfw"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urzHaF66BEB1"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\n","class MSELoss(nn.Module):\n","    def __init__(self, alpha=1.0):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.mse   = nn.MSELoss(reduction=\"none\")\n","\n","    def forward(self, outputs, targets, mask_s30):\n","        \"\"\"\n","        outputs: Tensor[B, C, H, W]\n","        targets: Tensor[B, C, H, W]\n","        mask_s30:Tensor[B, 1, H, W], mask=1 indicates valid pixels\n","        \"\"\"\n","        # Calculate per-pixel MSE\n","        loss_map = self.mse(outputs, targets)  # [B, C, H, W]\n","        # Expand mask to channel dimension\n","        mask_expand = mask_s30.expand_as(loss_map)  # [B, C, H, W]\n","        valid_pixels = torch.sum(mask_expand)  # Number of valid elements\n","        if valid_pixels > 0:\n","            main_loss = torch.sum(loss_map * mask_expand) / valid_pixels\n","        else:\n","            main_loss = torch.tensor(0.0, device=outputs.device)\n","        return self.alpha * main_loss\n","\n","# ======= Modification: add warmup / transition parameters in parse_args =======\n","def parse_args(argv=None):\n","    \"\"\"Argument parser for GAN training\"\"\"\n","    parser = argparse.ArgumentParser(\n","        description=\"GAN training script for multimodal image reconstruction with Warm-up/Transition strategy\"\n","    )\n","\n","    # Basic arguments\n","    parser.add_argument(\"--mode\", type=str, choices=[\"train\", \"test\"], default=\"train\")\n","    parser.add_argument(\"--model\", type=str, required=True, help=\"Model name (must have generator and discriminator)\")\n","    parser.add_argument(\"--loss\", type=str, required=True, help=\"Loss name for reconstruction\")\n","    parser.add_argument(\"--data_dir\", dest=\"data_dir\", type=str, default=\"data\", help=\"Data directory\")\n","    parser.add_argument(\"--batch_size\", dest=\"batch_size\", type=int, default=32)\n","    parser.add_argument(\"--epochs\", type=int, default=100)\n","    parser.add_argument(\"--gpu\", type=int, default=0)\n","    parser.add_argument(\"--ckpt_dir\", dest=\"ckpt_dir\", type=str, default=\"checkpoints\")\n","    parser.add_argument(\"--log_dir\", dest=\"log_dir\", type=str, default=\"logs\")\n","    parser.add_argument(\"--plot_dir\", dest=\"plot_dir\", type=str, default=\"plots\")\n","    parser.add_argument(\"--resume\", type=str, default=None)\n","\n","    # GAN-specific arguments\n","    parser.add_argument(\"--gan_mode\", dest=\"gan_mode\", type=str, choices=[\"vanilla\", \"wgan-gp\"], default=\"wgan-gp\")\n","    parser.add_argument(\"--d_steps\", dest=\"d_steps\", type=int, default=5, help=\"Discriminator steps per generator step\")\n","    parser.add_argument(\"--g_steps\", dest=\"g_steps\",type=int, default=1,help=\"Generator steps per discriminator step\")\n","    parser.add_argument(\"--gp_weight\", dest=\"gp_weight\", type=float, default=10.0, help=\"Gradient penalty weight\")\n","    parser.add_argument(\"--adv_weight\", dest=\"adv_weight\", type=float, default=0.01, help=\"Final adversarial loss weight for generator\")\n","    parser.add_argument(\"--lr_g\", dest=\"lr_g\", type=float, default=1e-4, help=\"Generator learning rate\")\n","    parser.add_argument(\"--lr_d\", dest=\"lr_d\", type=float, default=1e-4, help=\"Discriminator learning rate\")\n","    parser.add_argument(\"--weight_decay\", dest=\"weight_decay\", type=float, default=1e-5)\n","    parser.add_argument(\"--use_amp\", dest=\"use_amp\", action=\"store_true\", help=\"Use automatic mixed precision\")\n","\n","    # ======= Add warm-up and transition hyperparameters =======\n","    parser.add_argument(\"--warmup_epochs\", dest=\"warmup_epochs\", type=int, default=5,\n","                        help=\"Number of initial epochs using only reconstruction loss (adv_weight=0, don't update D)\")\n","    parser.add_argument(\"--transition_epochs\", dest=\"transition_epochs\", type=int, default=10,\n","                        help=\"Number of epochs to linearly increase adv_weight from 0→adv_weight\")\n","\n","    return parser.parse_args(argv)\n","\n","class OptimizedPatchDataset(Dataset):\n","    \"\"\"Dataset class for loading .pt files with caching,\n","    automatically removing samples whose L30, S1, Planet mask all equal zero.\n","    \"\"\"\n","    def __init__(self, data_dir, cache_size=50, map_location=\"cpu\"):\n","        self.data_dir = Path(data_dir)\n","        all_files = sorted(self.data_dir.glob(\"sample_*.pt\"))\n","        if not all_files:\n","            raise RuntimeError(f\"[OptimizedPatchDataset] No sample_*.pt files found in {self.data_dir}\")\n","\n","        # Filter: only keep samples with at least one non-zero mask\n","        valid_files = []\n","        for p in all_files:\n","            sample = torch.load(p, map_location=map_location)\n","            m0 = sample.get('mask_l30')\n","            m1 = sample.get('mask_s1')\n","            m2 = sample.get('mask_planet')\n","            # Keep if any mask is not all zeros\n","            if not ((m0.sum()==0) and (m1.sum()==0) and (m2.sum()==0)):\n","                valid_files.append(p)\n","        if not valid_files:\n","            raise RuntimeError(\"[OptimizedPatchDataset] All samples have zero masks!\")\n","\n","        self.files = valid_files\n","        self.cache = {}\n","        self.cache_size = cache_size\n","        self.map_location = map_location\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        if idx in self.cache:\n","            return self.cache[idx]\n","        sample = torch.load(self.files[idx], map_location=self.map_location)\n","        # Type adjustment & contiguous\n","        for key, value in sample.items():\n","            if isinstance(value, torch.Tensor):\n","                if value.dtype == torch.float64:\n","                    value = value.float()\n","                sample[key] = value.contiguous()\n","        # Cache\n","        if len(self.cache) < self.cache_size:\n","            self.cache[idx] = sample\n","        return sample\n","\n","\n","# Metric functions (remain unchanged)\n","def psnr_masked(img_ref, img_test, valid_mask, data_range=1.0):\n","    \"\"\"Calculate PSNR on masked regions\"\"\"\n","    if img_ref.shape != img_test.shape:\n","        raise ValueError(\"[psnr_masked] Shape mismatch\")\n","    if valid_mask.shape != img_ref.shape[1:]:\n","        raise ValueError(f\"[psnr_masked] Mask shape mismatch\")\n","\n","    I = img_ref.astype(np.float64)\n","    K = img_test.astype(np.float64)\n","    num_valid_pixels = np.sum(valid_mask)\n","    if num_valid_pixels == 0:\n","        return np.nan\n","\n","    squared_error = (I - K) ** 2\n","    mask_chw = np.expand_dims(valid_mask, axis=0).repeat(I.shape[0], axis=0)\n","    masked_squared = squared_error[mask_chw > 0]\n","    mse_masked = np.sum(masked_squared) / (num_valid_pixels * I.shape[0])\n","    if mse_masked <= 0:\n","        return float('inf')\n","    psnr_val = 10.0 * np.log10((data_range ** 2) / mse_masked)\n","    return float(psnr_val)\n","\n","def ssim_eroded_mask(img_ref, img_test, valid_mask, max_val=1.0, **ssim_kwargs):\n","    \"\"\"Calculate SSIM with eroded mask\"\"\"\n","    if img_ref.shape != img_test.shape:\n","        raise ValueError(\"[ssim_eroded_mask] Shape mismatch\")\n","\n","    C, H, W = img_ref.shape\n","    orig_mask = valid_mask > 0\n","    win_size = ssim_kwargs.pop('win_size', min(3, H, W))\n","    if win_size % 2 == 0:\n","        win_size -= 1\n","    if win_size < 3:\n","        return np.nan\n","\n","    struct_el = np.ones((win_size, win_size), dtype=bool)\n","    core_mask = binary_erosion(orig_mask, structure=struct_el, border_value=0)\n","    if np.count_nonzero(core_mask) == 0:\n","        return np.nan\n","\n","    ssim_vals = []\n","    for c in range(C):\n","        ref_chan = img_ref[c, :, :]\n","        test_chan = img_test[c, :, :]\n","        try:\n","            _, ssim_map = ssim(ref_chan, test_chan, data_range=max_val, full=True, **ssim_kwargs)\n","            ssim_vals.append(np.mean(ssim_map[core_mask]))\n","        except Exception as e:\n","            print(f\"[ssim_eroded_mask] Warning: Channel {c} SSIM failed: {e}\")\n","            ssim_vals.append(np.nan)\n","\n","    return float(np.nanmean(ssim_vals))\n","\n","def sam_masked(img_ref, img_test, valid_mask):\n","\n","    \"\"\"Calculate Spectral Angle Mapper on masked regions\"\"\"\n","    if img_ref.shape != img_test.shape:\n","        raise ValueError(\"[sam_masked] Shape mismatch\")\n","\n","    C, H, W = img_ref.shape\n","    I = img_ref.astype(np.float64)\n","    K = img_test.astype(np.float64)\n","\n","    mask_bool = valid_mask > 0\n","    if not np.any(mask_bool):\n","        return np.nan\n","\n","    I_flat = I[:, mask_bool]\n","    K_flat = K[:, mask_bool]\n","\n","    dot = np.sum(I_flat * K_flat, axis=0)\n","    norm_I = np.linalg.norm(I_flat, axis=0)\n","    norm_K = np.linalg.norm(K_flat, axis=0)\n","    denom = norm_I * norm_K\n","    valid_idx = denom > 0\n","    if not np.any(valid_idx):\n","        return np.nan\n","\n","    cos_theta = dot[valid_idx] / denom[valid_idx]\n","    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n","    angles = np.arccos(cos_theta)\n","    sam_deg = np.degrees(angles)\n","    return float(np.mean(sam_deg))\n","\n","def psnr_masked_gpu_batch(\n","    img_ref: torch.Tensor,   # shape (B, C, H, W)\n","    img_test: torch.Tensor,  # shape (B, C, H, W)\n","    valid_mask: torch.Tensor,# shape (B, 1, H, W) or (B, H, W)\n","    data_range: float = 1.0\n",") -> torch.Tensor:\n","    \"\"\"\n","    Batch Masked PSNR on GPU. Returns a tensor of shape (B,).\n","    \"\"\"\n","    B = img_ref.shape[0]\n","\n","    # Ensure mask shape is (B, 1, H, W)\n","    if valid_mask.dim() == 3:\n","        valid_mask = valid_mask.unsqueeze(1)\n","\n","    # Compute squared error\n","    se = (img_ref - img_test).pow(2)  # (B, C, H, W)\n","\n","    # Count valid pixels per sample\n","    num_pixels = valid_mask.sum(dim=(1, 2, 3))  # (B,)\n","    num_pixels = num_pixels * img_ref.shape[1]  # multiply by channels\n","\n","    # Mask and sum squared errors\n","    se_masked = se * valid_mask  # (B, C, H, W)\n","    mse = se_masked.sum(dim=(1, 2, 3)) / num_pixels.clamp(min=1)  # (B,)\n","\n","    # Compute PSNR\n","    psnr = 10.0 * torch.log10((data_range ** 2) / mse.clamp(min=1e-10))\n","\n","    # Handle invalid samples (no valid pixels)\n","    psnr = torch.where(num_pixels > 0, psnr, torch.tensor(float('nan'), device=img_ref.device))\n","\n","    return psnr  # (B,)\n","\n","def ssim_eroded_mask_gpu_batch(\n","    img_ref: torch.Tensor,\n","    img_test: torch.Tensor,\n","    valid_mask: torch.Tensor,\n","    window_size: int = 3,\n","    data_range: float = 1.0\n",") -> torch.Tensor:\n","    \"\"\"\n","    Corrected version: uses the same Gaussian window parameters as kornia\n","    \"\"\"\n","    B, C, H, W = img_ref.shape\n","\n","    if valid_mask.dim() == 3:\n","        valid_mask = valid_mask.unsqueeze(1)\n","    valid_mask = valid_mask.float()\n","\n","    # SSIM constants\n","    C1 = (0.01 * data_range) ** 2\n","    C2 = (0.03 * data_range) ** 2\n","\n","    # Create Gaussian window - use the same parameters as kornia\n","    sigma = 1.5  # kornia's default value\n","    coords = torch.arange(window_size, device=img_ref.device, dtype=img_ref.dtype)\n","    coords = coords - (window_size - 1) / 2\n","    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n","    g = g / g.sum()\n","    window = g.unsqueeze(0) * g.unsqueeze(1)\n","    window = window.unsqueeze(0).unsqueeze(0)\n","\n","    # Normalize window\n","    window = window / window.sum()\n","\n","    # Expand to all channels\n","    window = window.expand(C, 1, window_size, window_size).contiguous()\n","\n","    # Calculate local statistics\n","    pad = window_size // 2\n","\n","    mu1 = F.conv2d(img_ref, window, padding=pad, groups=C)\n","    mu2 = F.conv2d(img_test, window, padding=pad, groups=C)\n","\n","    mu1_sq = mu1.pow(2)\n","    mu2_sq = mu2.pow(2)\n","    mu1_mu2 = mu1 * mu2\n","\n","    sigma1_sq = F.conv2d(img_ref.pow(2), window, padding=pad, groups=C) - mu1_sq\n","    sigma2_sq = F.conv2d(img_test.pow(2), window, padding=pad, groups=C) - mu2_sq\n","    sigma12 = F.conv2d(img_ref * img_test, window, padding=pad, groups=C) - mu1_mu2\n","\n","    # Calculate SSIM\n","    numerator = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)\n","    denominator = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n","    ssim_map = numerator / denominator\n","\n","    # Average across channel dimension\n","    ssim_map = ssim_map.mean(dim=1, keepdim=True)\n","\n","    # Erode mask\n","    kernel = torch.ones((window_size, window_size), device=valid_mask.device)\n","    mask_eroded = erosion(valid_mask, kernel, border_type='constant', border_value=0.0)\n","    mask_eroded = (mask_eroded > 0.5).float()\n","\n","    # Calculate masked mean\n","    valid_pixels = mask_eroded.sum(dim=(1, 2, 3))\n","    ssim_masked = ssim_map * mask_eroded\n","    ssim_sum = ssim_masked.sum(dim=(1, 2, 3))\n","\n","    ssim_mean = torch.where(\n","        valid_pixels > 0,\n","        ssim_sum / valid_pixels,\n","        torch.tensor(float('nan'), device=img_ref.device)\n","    )\n","\n","    return ssim_mean\n","\n","def sam_masked_gpu_batch(\n","    img_ref: torch.Tensor,    # (B, C, H, W)\n","    img_pred: torch.Tensor,   # (B, C, H, W)\n","    valid_mask: torch.Tensor, # (B, 1, H, W) or (B, H, W)\n","    eps: float = 1e-8\n",") -> torch.Tensor:\n","    \"\"\"\n","    Batch Masked Spectral Angle Mapper on GPU. Returns a tensor of shape (B,) in degrees.\n","    \"\"\"\n","    B, C, H, W = img_ref.shape\n","\n","    # Ensure mask shape is (B, H, W)\n","    if valid_mask.dim() == 4:\n","        valid_mask = valid_mask.squeeze(1)\n","    elif valid_mask.dim() == 2:\n","        valid_mask = valid_mask.unsqueeze(0).expand(B, -1, -1)\n","\n","    # Reshape for batch processing\n","    img_ref_flat = img_ref.view(B, C, -1)  # (B, C, H*W)\n","    img_pred_flat = img_pred.view(B, C, -1)\n","    mask_flat = valid_mask.view(B, -1) > 0  # (B, H*W)\n","\n","    # Compute spectral angles for all pixels\n","    dot_product = (img_ref_flat * img_pred_flat).sum(dim=1)  # (B, H*W)\n","    norm_ref = img_ref_flat.norm(dim=1)  # (B, H*W)\n","    norm_pred = img_pred_flat.norm(dim=1)\n","\n","    # Avoid division by zero\n","    denominator = (norm_ref * norm_pred).clamp(min=eps)\n","    cos_theta = (dot_product / denominator).clamp(-1.0, 1.0)\n","\n","    # Convert to angles in degrees\n","    angles = torch.acos(cos_theta) * (180.0 / torch.pi)  # (B, H*W)\n","\n","    # Apply mask and compute mean for each sample\n","    sam_mean = torch.zeros(B, device=img_ref.device)\n","    for b in range(B):\n","        valid_angles = angles[b][mask_flat[b]]\n","        if valid_angles.numel() > 0:\n","            sam_mean[b] = valid_angles.mean()\n","        else:\n","            sam_mean[b] = float('nan')\n","\n","    return sam_mean  # (B,)\n","\n","\n","# Model and loss loading functions (remain unchanged)\n","def get_model_class(model_name: str):\n","    \"\"\"Dynamically load model class\"\"\"\n","    module_path = f\"Models.{model_name}\"\n","    try:\n","        module = importlib.import_module(module_path)\n","    except ImportError as e:\n","        raise ImportError(f\"[get_model_class] Cannot import {module_path}: {e}\")\n","\n","    if hasattr(module, \"MODEL_CLASS\"):\n","        return getattr(module, \"MODEL_CLASS\")\n","    else:\n","        raise AttributeError(f\"[get_model_class] {module_path}.py must define MODEL_CLASS\")\n","\n","def get_loss_class(loss_name: str):\n","    \"\"\"Dynamically load loss class\"\"\"\n","    module_path = f\"Losses.{loss_name}\"\n","    try:\n","        module = importlib.import_module(module_path)\n","    except ImportError as e:\n","        raise ImportError(f\"[get_loss_class] Cannot import {module_path}: {e}\")\n","\n","    if hasattr(module, \"LOSS_CLASS\"):\n","        return getattr(module, \"LOSS_CLASS\")\n","    else:\n","        raise AttributeError(f\"[get_loss_class] {module_path}.py must define LOSS_CLASS\")\n","def init_weights(m):\n","    \"\"\"Initialize model weights.\"\"\"\n","    if isinstance(m, (nn.Conv2d, nn.Linear)):\n","        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n","        if m.bias is not None:\n","            nn.init.zeros_(m.bias)\n","def GenerateMask(x,dim=1):\n","    mask = (x != 0).float().sum(dim=dim)\n","    mask = mask.unsqueeze(1)\n","    return mask\n","def compute_gradient_penalty(discriminator, real_samples, fake_samples, mask_s30,device):\n","    \"\"\"\n","    Modified version: compute gradient penalty only for S30 images\n","    \"\"\"\n","    batch_size = real_samples[0].shape[0]\n","    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n","\n","    # Interpolate only for S30 (as it is the generation target)\n","    l30, s1, planet, s30_real = real_samples\n","    _, _, _, s30_fake = fake_samples\n","\n","    s30_interp = alpha * s30_real + (1 - alpha) * s30_fake\n","    s30_interp.requires_grad_(True)\n","\n","    # Get discriminator output\n","    # mask_l30, mask_s1, mask_planet, mask_s30 = masks\n","    # mask_s30=GenerateMask(s30_real,1)\n","    disc_interp = discriminator(l30,s1,planet,s30_interp, mask_s30)\n","\n","    # Handle multi-scale output\n","    if isinstance(disc_interp, list):\n","        # Average gradient penalty across all scales\n","        gradient_penalty = 0\n","        for scale_output in disc_interp:\n","            gradients = torch.autograd.grad(\n","                outputs=scale_output,\n","                inputs=s30_interp,\n","                grad_outputs=torch.ones_like(scale_output),\n","                create_graph=True,\n","                retain_graph=True,\n","                only_inputs=True\n","            )[0]\n","\n","            gradients = gradients.view(batch_size, -1)\n","            gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","            gradient_penalty += gp\n","\n","        gradient_penalty = gradient_penalty / len(disc_interp)\n","    else:\n","        # Single-scale discriminator\n","        gradients = torch.autograd.grad(\n","            outputs=disc_interp,\n","            inputs=s30_interp,\n","            grad_outputs=torch.ones_like(disc_interp),\n","            create_graph=True,\n","            retain_graph=True,\n","            only_inputs=True\n","        )[0]\n","\n","        gradients = gradients.view(batch_size, -1)\n","        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","\n","    return gradient_penalty\n","def save_epoch_metrics(history, epoch, log_dir,log_name):\n","    \"\"\"Save all metrics for the current epoch\"\"\"\n","    # Create dictionary with current epoch metrics\n","    current_metrics = {\n","        \"epoch\": epoch + 1,\n","        \"train_g_loss\": history[\"train_g_loss\"][-1],\n","        \"train_d_loss\": history[\"train_d_loss\"][-1],\n","        \"train_rec_loss\": history[\"train_rec_loss\"][-1],\n","        \"train_adv_loss\": history[\"train_adv_loss\"][-1],\n","        \"val_rec_loss\": history[\"val_rec_loss\"][-1],\n","        \"val_d_real\": history[\"val_d_real\"][-1],\n","        \"val_d_fake\": history[\"val_d_fake\"][-1],\n","        \"lr_g\": history[\"lr_g\"][-1],\n","        \"lr_d\": history[\"lr_d\"][-1]\n","    }\n","\n","    # Continuously update a single CSV file (easier to import into analysis tools)\n","    csv_file = log_dir / f\"training_metrics_{log_name}.csv\"\n","\n","    # If file doesn't exist, create and write header\n","    if not csv_file.exists():\n","        with open(csv_file, 'w') as f:\n","            header = \",\".join(current_metrics.keys())\n","            f.write(f\"{header}\\n\")\n","\n","    # Append current epoch values\n","    with open(csv_file, 'a') as f:\n","        values = \",\".join(str(v) for v in current_metrics.values())\n","        f.write(f\"{values}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"AI9Txv5Rmm-w"},"source":["#Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cDkAkvP7ORyN"},"outputs":[],"source":["def main(args):\n","    # Device selection\n","    if args.gpu >= 0 and torch.cuda.is_available():\n","        device = torch.device(f\"cuda:{args.gpu}\")\n","    else:\n","        device = torch.device(\"cpu\")\n","    print(f\"[INFO] Using device: {device}\")\n","\n","    # Create directories\n","    ckpt_dir = Path(args.ckpt_dir)\n","    ckpt_dir.mkdir(parents=True, exist_ok=True)\n","    log_dir = Path(args.log_dir)\n","    log_dir.mkdir(parents=True, exist_ok=True)\n","    plot_dir = Path(args.plot_dir)\n","    plot_dir.mkdir(parents=True, exist_ok=True)\n","\n","    model = UnetGAN(use_meta=False, use_selfattention=True,\n","                     use_spatial_attention=True).to(device)#True,False\n","\n","    if not (hasattr(model, 'generator') and hasattr(model, 'discriminator')):\n","        raise AttributeError(f\"Model '{args.model}' must have 'generator' and 'discriminator' attributes\")\n","    generator = model.generator\n","    discriminator = model.discriminator\n","\n","    # Count parameters\n","    g_params = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n","    d_params = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n","    print(f\"[INFO] Generator parameters: {g_params:,}\")\n","    print(f\"[INFO] Discriminator parameters: {d_params:,}\")\n","\n","    # Create optimizers\n","    optimizer_g = optim.AdamW(generator.parameters(), lr=args.lr_g, weight_decay=args.weight_decay)\n","    optimizer_d = optim.AdamW(discriminator.parameters(), lr=args.lr_d, weight_decay=args.weight_decay)\n","\n","    # Learning rate schedulers\n","    # scheduler_g = optim.lr_scheduler.ReduceLROnPlateau(optimizer_g, mode=\"min\", factor=0.5, patience=5)\n","    # scheduler_d = optim.lr_scheduler.ReduceLROnPlateau(optimizer_d, mode=\"min\", factor=0.5, patience=5)\n","\n","    # Loss functions\n","    criterion_rec = MSELoss()  # Reconstruction loss\n","    if args.gan_mode == \"vanilla\":\n","        criterion_adv = nn.BCEWithLogitsLoss()\n","\n","    # AMP setup\n","    use_amp = args.use_amp and device.type.startswith(\"cuda\")\n","    scaler_g = torch.amp.GradScaler() if use_amp else None\n","    scaler_d = torch.amp.GradScaler() if use_amp else None\n","    # Prepare datasets\n","    train_dir = Path(args.data_dir) / \"train\"\n","    val_dir = Path(args.data_dir) / \"val\"\n","    test_dir = Path(args.data_dir) / \"test\"\n","\n","    for d in (train_dir, val_dir, test_dir):\n","        if not d.exists():\n","            raise RuntimeError(f\"[ERROR] Directory '{d}' does not exist\")\n","\n","    train_dataset = OptimizedPatchDataset(train_dir, cache_size=100)\n","    val_dataset = OptimizedPatchDataset(val_dir, cache_size=100)\n","    test_dataset = OptimizedPatchDataset(test_dir, cache_size=100)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0, pin_memory=True)\n","\n","    print(f\"[INFO] Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n","    # Learning rate schedulers\n","    per_epoch_iteration = len(train_dataset) // args.batch_size\n","    total_iteration_g = per_epoch_iteration*(args.warmup_epochs+(args.epochs-args.warmup_epochs)*args.g_steps)\n","    total_iteration_d = per_epoch_iteration*(args.epochs-args.warmup_epochs)*args.d_steps\n","\n","    scheduler_g = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_g, total_iteration_g, eta_min=1e-6)\n","    scheduler_d = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_d, total_iteration_d, eta_min=1e-6)\n","\n","    # Load checkpoint if specified\n","    start_epoch = 0\n","    best_val_loss = float(\"inf\")\n","\n","    # Training history for plotting\n","    history = {\n","        'train_g_loss': [],\n","        'train_rec_loss': [],      # New addition\n","        'train_adv_loss': [],\n","        'train_d_loss': [],\n","        'train_d_real': [],\n","        'train_d_fake': [],\n","        'train_gp': [],\n","        'val_rec_loss': [],\n","        'val_d_real': [],\n","        'val_d_fake': [],\n","        'lr_g': [],\n","        'lr_d': []\n","    }\n","\n","    if args.resume:\n","        if os.path.isfile(args.resume):\n","            ckpt = torch.load(args.resume, map_location=device, weights_only=False)\n","            generator.load_state_dict(ckpt[\"generator_state_dict\"])\n","            discriminator.load_state_dict(ckpt[\"discriminator_state_dict\"])\n","            optimizer_g.load_state_dict(ckpt[\"optimizer_g_state_dict\"])\n","            optimizer_d.load_state_dict(ckpt[\"optimizer_d_state_dict\"])\n","            scheduler_g.load_state_dict(ckpt[\"scheduler_g_state_dict\"])\n","            scheduler_d.load_state_dict(ckpt[\"scheduler_d_state_dict\"])\n","            start_epoch = ckpt.get(\"epoch\", 0)\n","            best_val_loss = ckpt.get(\"best_val_loss\", best_val_loss)\n","            history = ckpt.get(\"history\", history)\n","            print(f\"[INFO] Resumed from epoch {start_epoch}\")\n","\n","    # ======= Modification: add Warm-up/Transition logic in train_one_epoch =======\n","    def train_one_epoch(epoch_idx):\n","        \"\"\"GAN training for one epoch, with Warm-up→Transition→Full-Adversarial\"\"\"\n","        generator.train()\n","        discriminator.train()\n","\n","        # Calculate current epoch adversarial loss weight adv_w\n","        # 1) warmup phase: adv_weight_current = 0\n","        # 2) transition phase: adv_weight_current linearly from 0 to args.adv_weight\n","        # 3) full phase: adv_weight_current = args.adv_weight\n","        if epoch_idx < args.warmup_epochs:\n","            adv_weight_current = 0.0\n","            do_discriminator = False      # Don't update D during warmup\n","        elif epoch_idx < args.warmup_epochs + args.transition_epochs:\n","            # Transition phase, linear interpolation\n","            alpha = (epoch_idx - args.warmup_epochs + 1) / args.transition_epochs\n","            adv_weight_current = args.adv_weight * min(alpha, 1.0)\n","            do_discriminator = True\n","        else:\n","            adv_weight_current = args.adv_weight\n","            do_discriminator = True\n","\n","        epoch_metrics = {\n","            'g_loss': [], 'd_loss': [], 'd_real': [],\n","            'd_fake': [], 'gp': [], 'rec_loss': [],\n","            'train_adv_loss':[]\n","        }#,'train_rec_loss':[]\n","\n","        pbar = tqdm(train_loader, desc=f\"Epoch {epoch_idx+1}/{args.epochs}\")\n","\n","        for batch_idx, batch in enumerate(pbar):\n","            # Move data to device\n","            l30_img = batch[\"l30_img\"].to(device, non_blocking=True)\n","            # mask_l30 = batch[\"mask_l30\"].to(device, non_blocking=True)\n","            l30_meta = batch[\"l30_meta\"].to(device, non_blocking=True)\n","            s1_img = batch[\"s1_img\"].to(device, non_blocking=True)\n","            # mask_s1 = batch[\"mask_s1\"].to(device, non_blocking=True)\n","            s1_meta = batch[\"s1_meta\"].to(device, non_blocking=True)\n","            planet_img = batch[\"planet_img\"].to(device, non_blocking=True)\n","            # mask_planet = batch[\"mask_planet\"].to(device, non_blocking=True)\n","            planet_meta = batch[\"planet_meta\"].to(device, non_blocking=True)\n","            s30_gt = batch[\"s30_img_gt\"].to(device, non_blocking=True)\n","            mask_s30 = batch[\"mask_s30\"].to(device, non_blocking=True)\n","\n","            batch_size = l30_img.shape[0]\n","\n","            # =====================\n","            # 1) If in Warm-up phase, only train Generator with reconstruction, don't update discriminator D\n","            # =====================\n","            if not do_discriminator:\n","                optimizer_g.zero_grad()\n","\n","                # Only calculate reconstruction loss\n","                fake_s30 = generator(\n","                    l30_img, l30_meta,\n","                    s1_img,  s1_meta,\n","                    planet_img, planet_meta\n","                )\n","                loss_rec = criterion_rec(fake_s30, s30_gt, mask_s30)\n","                ssims=ssim_eroded_mask_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","                sams=sam_masked_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","                psnrs=psnr_masked_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","\n","                loss_ssim  = (1 - ssims)   # Structure loss\n","                loss_sam   = sams/180         # Spectral angle loss\n","                loss_psnr  = 1.0 - psnrs/50.0\n","                loss_rec = 1*loss_rec + 0.5*loss_ssim + 0.5*loss_sam + 0.2 * loss_psnr\n","\n","                loss_g = loss_rec  # adv_weight_current == 0, so adversarial loss is 0\n","\n","                if use_amp:\n","                    scaler_g.scale(loss_g).backward()\n","                    scaler_g.unscale_(optimizer_g)\n","                    torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n","                    scaler_g.step(optimizer_g)\n","                    scaler_g.update()\n","                else:\n","                    loss_g.backward()\n","                    torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n","                    optimizer_g.step()\n","                scheduler_g.step()\n","                # Record metrics\n","                epoch_metrics['g_loss'].append(loss_g.item())\n","                epoch_metrics['d_loss'].append(0.0)\n","                epoch_metrics['d_real'].append(0.0)\n","                epoch_metrics['d_fake'].append(0.0)\n","                epoch_metrics['gp'].append(0.0)\n","                epoch_metrics['rec_loss'].append(loss_rec.item())\n","                epoch_metrics['train_adv_loss'].append(loss_g.item()-loss_rec.item())\n","                # epoch_metrics['train_rec_loss'].append(train_metrics['rec_loss'])\n","\n","                pbar.set_postfix({\n","                    'G(rec)': f\"{loss_rec.item():.3e}\",\n","                    'advW': f\"{adv_weight_current:.2e}\"\n","                })\n","                continue  # Skip to next batch\n","\n","            # =====================\n","            # 2) If in Transition / Full phase, first update discriminator D, then update generator G (with dynamic adv_weight_current)\n","            # =====================\n","\n","            # ---------------------\n","            # 2.1 Train Discriminator\n","            # ---------------------\n","            d_losses_step = []\n","            d_real_scores = []\n","            d_fake_scores = []\n","            gp_values = []\n","\n","            for _ in range(args.d_steps):\n","                optimizer_d.zero_grad()\n","\n","                # Generate fake images (detach)\n","                with torch.no_grad():\n","                    fake_s30 = generator(\n","                        l30_img,  l30_meta,\n","                        s1_img,  s1_meta,\n","                        planet_img,  planet_meta\n","                    )\n","                    mask_ext = mask_s30.expand(-1, fake_s30.size(1), -1, -1)\n","                    fake_s30 = fake_s30 * mask_ext\n","                if use_amp:\n","                    with torch.amp.autocast(device_type=device.type):\n","                        # Discriminator output on real samples\n","                        d_real = discriminator(\n","                            l30_img, s1_img,\n","                            planet_img, s30_gt, mask_s30\n","                        )\n","                        # Discriminator output on fake samples\n","                        d_fake = discriminator(\n","                            l30_img,  s1_img,\n","                            planet_img, fake_s30.detach(), mask_s30\n","                        )\n","\n","                        # Calculate D loss for multiple scales\n","                        if isinstance(d_real, list):\n","                            loss_d_real = sum(-torch.mean(dr) for dr in d_real) / len(d_real)\n","                            loss_d_fake = sum(torch.mean(df) for df in d_fake) / len(d_fake)\n","                            d_real_score = sum(dr.mean().item() for dr in d_real) / len(d_real)\n","                            d_fake_score = sum(df.mean().item() for df in d_fake) / len(d_fake)\n","                        else:\n","                            loss_d_real = -torch.mean(d_real)\n","                            loss_d_fake = torch.mean(d_fake)\n","                            d_real_score = d_real.mean().item()\n","                            d_fake_score = d_fake.mean().item()\n","\n","                        if args.gan_mode == \"wgan-gp\":\n","                            # Calculate gradient penalty\n","                            gp = compute_gradient_penalty(\n","                                discriminator,\n","                                [l30_img, s1_img, planet_img, s30_gt],\n","                                [l30_img, s1_img, planet_img, fake_s30.detach()],mask_s30,\n","                                device\n","                            )\n","                            gp = torch.clamp(gp, 0, 50)  # Prevent gradient explosion\n","                            loss_d = loss_d_real + loss_d_fake + args.gp_weight * gp\n","                            gp_values.append(gp.item())\n","                        else:\n","                            loss_d = loss_d_real + loss_d_fake\n","\n","                    scaler_d.scale(loss_d).backward()\n","                    scaler_d.unscale_(optimizer_d)\n","                    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)\n","                    scaler_d.step(optimizer_d)\n","                    scaler_d.update()\n","                else:\n","                    d_real = discriminator(\n","                        l30_img,  s1_img,\n","                        planet_img, s30_gt, mask_s30\n","                    )\n","                    d_fake = discriminator(\n","                        l30_img,  s1_img,\n","                        planet_img, fake_s30.detach(), mask_s30\n","                    )\n","\n","                    if isinstance(d_real, list):\n","                        loss_d_real = sum(-torch.mean(dr) for dr in d_real) / len(d_real)\n","                        loss_d_fake = sum(torch.mean(df) for df in d_fake) / len(d_fake)\n","                        d_real_score = sum(dr.mean().item() for dr in d_real) / len(d_real)\n","                        d_fake_score = sum(df.mean().item() for df in d_fake) / len(d_fake)\n","                    else:\n","                        loss_d_real = -torch.mean(d_real)\n","                        loss_d_fake = torch.mean(d_fake)\n","                        d_real_score = d_real.mean().item()\n","                        d_fake_score = d_fake.mean().item()\n","\n","                    if args.gan_mode == \"wgan-gp\":\n","                        gp = compute_gradient_penalty(\n","                            discriminator,\n","                            [l30_img, s1_img, planet_img, s30_gt],\n","                            [l30_img, s1_img, planet_img, fake_s30.detach()],mask_s30,\n","                            device\n","                        )\n","                        gp = torch.clamp(gp, 0, 50)  # Prevent gradient explosion\n","                        loss_d = loss_d_real + loss_d_fake + args.gp_weight * gp\n","                        gp_values.append(gp.item())\n","                    else:\n","                        loss_d = loss_d_real + loss_d_fake\n","\n","                    loss_d.backward()\n","                    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)\n","                    optimizer_d.step()\n","                scheduler_d.step()\n","                d_losses_step.append(loss_d.item())\n","                d_real_scores.append(d_real_score)\n","                d_fake_scores.append(d_fake_score)\n","\n","            # Calculate average D metrics\n","            avg_d_loss = np.mean(d_losses_step)\n","            avg_d_real = np.mean(d_real_scores)\n","            avg_d_fake = np.mean(d_fake_scores)\n","            avg_gp = np.mean(gp_values) if gp_values else 0\n","\n","            # ---------------------\n","            # 2.2 Train Generator\n","            # ---------------------\n","            rec_losses, adv_losses, total_losses = [], [], []\n","            for _ in range(args.g_steps):\n","                optimizer_g.zero_grad()\n","                fake_s30 = generator(\n","                    l30_img, l30_meta,\n","                    s1_img, s1_meta,\n","                    planet_img, planet_meta\n","                )\n","\n","                loss_rec = criterion_rec(fake_s30, s30_gt, mask_s30)\n","\n","                ssims=ssim_eroded_mask_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","                sams=sam_masked_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","                psnrs=psnr_masked_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","\n","                loss_ssim  = (1 - ssims)   # Structure loss\n","                loss_sam   = sams/180         # Spectral angle loss\n","                loss_psnr  = 1.0 - psnrs/50.0\n","                loss_rec = 1*loss_rec + 0.5*loss_ssim + 0.5*loss_sam + 0.2 * loss_psnr\n","\n","                d_fake_for_g = discriminator(\n","                    l30_img,  s1_img,\n","                    planet_img,  fake_s30, mask_s30\n","                )\n","                if isinstance(d_fake_for_g, list):\n","                    loss_adv = sum(-df.mean() for df in d_fake_for_g) / len(d_fake_for_g)\n","                else:\n","                    loss_adv = -d_fake_for_g.mean()\n","\n","                loss_g = loss_rec + adv_weight_current * loss_adv\n","                if use_amp:\n","                    scaler_g.scale(loss_g).backward()\n","                    scaler_g.unscale_(optimizer_g)\n","                    torch.nn.utils.clip_grad_norm_(generator.parameters(), 1.0)\n","                    scaler_g.step(optimizer_g)\n","                    scaler_g.update()\n","                else:\n","                    loss_g.backward()\n","                    torch.nn.utils.clip_grad_norm_(generator.parameters(), 1.0)\n","                    optimizer_g.step()\n","                scheduler_g.step()\n","                rec_losses.append(loss_rec.item())\n","                adv_losses.append((adv_weight_current * loss_adv).item())\n","                total_losses.append(loss_g.item())\n","\n","            # Average metrics from g_steps updates as this batch's metrics\n","            mean_rec   = sum(rec_losses)   / len(rec_losses)\n","            mean_adv   = sum(adv_losses)   / len(adv_losses)\n","            mean_total = sum(total_losses) / len(total_losses)\n","\n","            # Record this batch's metrics\n","            epoch_metrics['g_loss'].append(mean_total)\n","            epoch_metrics['rec_loss'].append(mean_rec)\n","            epoch_metrics['train_adv_loss'].append(mean_adv)\n","            epoch_metrics['d_loss'].append(avg_d_loss)\n","            epoch_metrics['d_real'].append(avg_d_real)\n","            epoch_metrics['d_fake'].append(avg_d_fake)\n","            epoch_metrics['gp'].append(avg_gp)\n","\n","\n","            # Update progress bar info\n","            pbar.set_postfix({\n","                'G': f\"{mean_total:.3e}\",\n","                'G(adv)': f\"{mean_adv:.3e}\",\n","                'G(rec)': f\"{mean_rec:.3e}\",\n","                'D': f\"{avg_d_loss:.3e}\",\n","                'Dr': f\"{avg_d_real:.3f}\",\n","                'Df': f\"{avg_d_fake:.3f}\",\n","                'advW': f\"{adv_weight_current:.2e}\"\n","\n","            })\n","\n","        # Return this epoch's average metrics\n","        return {k: np.mean(v) for k, v in epoch_metrics.items()}\n","\n","    # validate function remains unchanged\n","    def validate(epoch_idx):\n","        \"\"\"Validation with reconstruction loss and discriminator scores\"\"\"\n","        generator.eval()\n","        # discriminator.eval()\n","        discriminator.eval()\n","        val_metrics = {\n","            'rec_loss': [], 'd_real': [], 'd_fake': []\n","        }\n","\n","        if epoch_idx < args.warmup_epochs:\n","            do_discriminator = False      # Don't update D during warmup\n","        else:\n","            do_discriminator = True\n","\n","        with torch.no_grad():\n","            pbar = tqdm(val_loader, desc=\"[Validation]\")\n","            for batch in pbar:\n","                # Move data to device\n","                l30_img = batch[\"l30_img\"].to(device, non_blocking=True)\n","                # mask_l30 = batch[\"mask_l30\"].to(device, non_blocking=True)\n","                l30_meta = batch[\"l30_meta\"].to(device, non_blocking=True)\n","                s1_img = batch[\"s1_img\"].to(device, non_blocking=True)\n","                # mask_s1 = batch[\"mask_s1\"].to(device, non_blocking=True)\n","                s1_meta = batch[\"s1_meta\"].to(device, non_blocking=True)\n","                planet_img = batch[\"planet_img\"].to(device, non_blocking=True)\n","                # mask_planet = batch[\"mask_planet\"].to(device, non_blocking=True)\n","                planet_meta = batch[\"planet_meta\"].to(device, non_blocking=True)\n","                s30_gt = batch[\"s30_img_gt\"].to(device, non_blocking=True)\n","                mask_s30 = batch[\"mask_s30\"].to(device, non_blocking=True)\n","\n","                # Generate fake images\n","                fake_s30 = generator(\n","                    l30_img,  l30_meta,\n","                    s1_img,  s1_meta,\n","                    planet_img,  planet_meta\n","                )\n","                batch_size=mask_s30.shape[0]\n","                # Reconstruction loss\n","                rec_loss = criterion_rec(fake_s30, s30_gt, mask_s30)\n","\n","                ssims=ssim_eroded_mask_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","                sams=sam_masked_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","                psnrs=psnr_masked_gpu_batch(s30_gt, fake_s30, mask_s30).mean()\n","\n","                loss_ssim  = (1 - ssims)   # Structure loss\n","                loss_sam   = sams/180         # Spectral angle loss\n","                loss_psnr  = 1.0 - psnrs/50.0\n","                rec_loss = 1*rec_loss + 0.5*loss_ssim + 0.5*loss_sam + 0.2 * loss_psnr\n","\n","                val_metrics['rec_loss'].append(rec_loss.item())\n","                if do_discriminator == False:\n","                    d_real_score=0\n","                    d_fake_score=0\n","                    val_metrics['d_real'].append(d_real_score)\n","                    val_metrics['d_fake'].append(d_fake_score)\n","                # Discriminator scores\n","                elif do_discriminator == True:\n","                    d_real = discriminator(\n","                        l30_img, s1_img, planet_img, s30_gt, mask_s30\n","                    )\n","                    d_fake = discriminator(\n","                        l30_img, s1_img,planet_img, fake_s30, mask_s30\n","                    )\n","\n","                    if isinstance(d_real, list):\n","                        d_real_score = sum(dr.mean().item() for dr in d_real) / len(d_real)\n","                        d_fake_score = sum(df.mean().item() for df in d_fake) / len(d_fake)\n","                    else:\n","                        d_real_score = d_real.mean().item()\n","                        d_fake_score = d_fake.mean().item()\n","\n","                    val_metrics['d_real'].append(d_real_score)\n","                    val_metrics['d_fake'].append(d_fake_score)\n","\n","                pbar.set_postfix({\n","                    'rec': f\"{rec_loss.item():.3e}\",\n","                    'Dr': f\"{d_real_score:.3f}\",\n","                    'Df': f\"{d_fake_score:.3f}\"\n","                })\n","        # discriminator.eval()\n","        return {k: np.mean(v) for k, v in val_metrics.items()}\n","\n","    # test_and_evaluate remains unchanged\n","    def test_and_evaluate():\n","        \"\"\"Test evaluation with comprehensive metrics\"\"\"\n","        generator.eval()\n","\n","        mse_list, rmse_list, psnr_list, ssim_list, sam_list = [], [], [], [], []\n","        num_valid_samples = 0\n","\n","        save_samples = True\n","        num_samples_to_save = 10\n","        saved_cnt = 0\n","        sample_dir = log_dir / \"test_samples\"\n","        if save_samples:\n","            sample_dir.mkdir(parents=True, exist_ok=True)\n","\n","        with torch.no_grad():\n","            pbar = tqdm(test_loader, desc=\"[Test]\")\n","            for batch_idx, batch in enumerate(pbar):\n","                # Move data to device\n","                l30_img = batch[\"l30_img\"].to(device, non_blocking=True)\n","                # mask_l30 = batch[\"mask_l30\"].to(device, non_blocking=True)\n","                l30_meta = batch[\"l30_meta\"].to(device, non_blocking=True)\n","                s1_img = batch[\"s1_img\"].to(device, non_blocking=True)\n","                # mask_s1 = batch[\"mask_s1\"].to(device, non_blocking=True)\n","                s1_meta = batch[\"s1_meta\"].to(device, non_blocking=True)\n","                planet_img = batch[\"planet_img\"].to(device, non_blocking=True)\n","                # mask_planet = batch[\"mask_planet\"].to(device, non_blocking=True)\n","                planet_meta = batch[\"planet_meta\"].to(device, non_blocking=True)\n","                s30_gt = batch[\"s30_img_gt\"].to(device, non_blocking=True)\n","                mask_s30 = batch[\"mask_s30\"].to(device, non_blocking=True)\n","\n","                # Generate predictions\n","                outputs = generator(\n","                    l30_img,  l30_meta,\n","                    s1_img,  s1_meta,\n","                    planet_img,  planet_meta\n","                )\n","                mask_ext = mask_s30.expand(-1, outputs.size(1), -1, -1)\n","                outputs = outputs * mask_ext  # Apply mask to outputs here!\n","                # outputs = outputs * mask_s30\n","                pred_np = outputs.cpu().numpy()\n","                gt_np = s30_gt.cpu().numpy()\n","                mask_np = mask_s30.cpu().numpy().squeeze(1)\n","\n","                B = pred_np.shape[0]\n","                for i in range(B):\n","                    pred_i = pred_np[i]\n","                    gt_i = gt_np[i]\n","                    mask_i = mask_np[i]\n","\n","                    # Compute metrics\n","                    mse_map = (pred_i - gt_i) ** 2\n","                    num_valid_pixels = np.sum(mask_i) * pred_i.shape[0]\n","                    if num_valid_pixels > 0:\n","                        mse_val = np.sum(mse_map * mask_i[np.newaxis, ...]) / num_valid_pixels\n","                    else:\n","                        mse_val = np.nan\n","                    rmse_val = np.sqrt(mse_val) if not np.isnan(mse_val) else np.nan\n","\n","                    psnr_val = psnr_masked(gt_i, pred_i, mask_i, data_range=1.0)\n","                    ssim_val = ssim_eroded_mask(gt_i, pred_i, mask_i, max_val=1.0)\n","                    sam_val = sam_masked(gt_i, pred_i, mask_i)\n","\n","                    if not np.isnan(mse_val):\n","                        mse_list.append(mse_val)\n","                        rmse_list.append(rmse_val)\n","                        psnr_list.append(psnr_val)\n","                        ssim_list.append(ssim_val)\n","                        sam_list.append(sam_val)\n","                        num_valid_samples += 1\n","\n","                    # Save visualizations\n","                    if save_samples and saved_cnt < num_samples_to_save:\n","                        # Create RGB visualization\n","                        if pred_i.shape[0] >= 3:\n","                            pred_rgb = np.clip(pred_i[:3].transpose(1, 2, 0), 0, 1)\n","                            gt_rgb = np.clip(gt_i[:3].transpose(1, 2, 0), 0, 1)\n","                        else:\n","                            pred_rgb = np.repeat(pred_i[0:1].transpose(1, 2, 0), 3, axis=2)\n","                            gt_rgb = np.repeat(gt_i[0:1].transpose(1, 2, 0), 3, axis=2)\n","\n","                        # Create difference map\n","                        diff = np.abs(pred_rgb - gt_rgb)\n","\n","                        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","                        axes[0].imshow(gt_rgb)\n","                        axes[0].set_title(\"Ground Truth\")\n","                        axes[0].axis(\"off\")\n","                        axes[1].imshow(pred_rgb)\n","                        axes[1].set_title(f\"Prediction (PSNR: {psnr_val:.2f} dB)\")\n","                        axes[1].axis(\"off\")\n","                        axes[2].imshow(diff, cmap='hot')\n","                        axes[2].set_title(\"Absolute Difference\")\n","                        axes[2].axis(\"off\")\n","                        plt.tight_layout()\n","                        plt.savefig(sample_dir / f\"sample_{batch_idx:04d}_{i:02d}.png\")\n","                        plt.close(fig)\n","                        saved_cnt += 1\n","\n","                if mse_list:\n","                    pbar.set_postfix({\n","                        \"MSE\": f\"{np.mean(mse_list):.6f}\",\n","                        \"PSNR\": f\"{np.mean(psnr_list):.2f}\",\n","                        \"SSIM\": f\"{np.mean(ssim_list):.4f}\"\n","                    })\n","\n","        # Final results\n","        results = {\n","            \"mse_mean\": float(np.mean(mse_list)),\n","            \"mse_std\": float(np.std(mse_list)),\n","            \"rmse_mean\": float(np.mean(rmse_list)),\n","            \"rmse_std\": float(np.std(rmse_list)),\n","            \"psnr_mean\": float(np.mean(psnr_list)),\n","            \"psnr_std\": float(np.std(psnr_list)),\n","            \"ssim_mean\": float(np.mean(ssim_list)),\n","            \"ssim_std\": float(np.std(ssim_list)),\n","            \"sam_mean\": float(np.mean(sam_list)),\n","            \"sam_std\": float(np.std(sam_list)),\n","            \"num_valid_samples\": num_valid_samples\n","        }\n","\n","        # Save results\n","        results_file = log_dir / \"test_results.txt\"\n","        with open(results_file, \"w\") as f:\n","            f.write(\"===== Test Set Evaluation =====\\n\")\n","            f.write(f\"MSE:  {results['mse_mean']:.6f} ± {results['mse_std']:.6f}\\n\")\n","            f.write(f\"RMSE: {results['rmse_mean']:.6f} ± {results['rmse_std']:.6f}\\n\")\n","            f.write(f\"PSNR: {results['psnr_mean']:.4f} ± {results['psnr_std']:.4f} dB\\n\")\n","            f.write(f\"SSIM: {results['ssim_mean']:.4f} ± {results['ssim_std']:.4f}\\n\")\n","            f.write(f\"SAM:  {results['sam_mean']:.4f} ± {results['sam_std']:.4f} degrees\\n\")\n","            f.write(f\"Valid Samples: {results['num_valid_samples']}\\n\")\n","\n","        print(f\"\\n[INFO] Test results saved to {results_file}\")\n","        for k, v in results.items():\n","            if isinstance(v, float):\n","                print(f\"{k}: {v:.6f}\")\n","            else:\n","                print(f\"{k}: {v}\")\n","\n","        return results\n","\n","    # Test mode\n","    if args.mode == \"test\":\n","        print(\"[INFO] Running test evaluation only\")\n","        if args.resume is None:\n","            raise RuntimeError(\"Test mode requires --resume checkpoint\")\n","        test_results = test_and_evaluate()\n","        return\n","\n","    # Training loop\n","    print(\"\\n[INFO] Starting GAN training...\")\n","\n","    for epoch in range(start_epoch, args.epochs):\n","        epoch_start = time.time()\n","\n","        # Train (will do Warm-up / Transition / Full based on epoch internally)\n","        train_metrics = train_one_epoch(epoch)\n","\n","        # Validate\n","        val_metrics = validate(epoch)\n","\n","        # Update learning rates (only use validation reconstruction loss as metric)\n","        # scheduler_g.step(val_metrics['rec_loss'])\n","        # scheduler_d.step(val_metrics['rec_loss'])\n","\n","        # Record history\n","        history['train_g_loss'].append(train_metrics['g_loss'])\n","        history['train_adv_loss'].append(train_metrics['train_adv_loss'])\n","        history['train_rec_loss'].append(train_metrics['rec_loss'])\n","        history['train_d_loss'].append(train_metrics['d_loss'])\n","        history['train_d_real'].append(train_metrics['d_real'])\n","        history['train_d_fake'].append(train_metrics['d_fake'])\n","        history['train_gp'].append(train_metrics['gp'])\n","        history['val_rec_loss'].append(val_metrics['rec_loss'])\n","        history['val_d_real'].append(val_metrics['d_real'])\n","        history['val_d_fake'].append(val_metrics['d_fake'])\n","        history['lr_g'].append(optimizer_g.param_groups[0]['lr'])\n","        history['lr_d'].append(optimizer_d.param_groups[0]['lr'])\n","\n","        # Print epoch summary\n","        elapsed = time.time() - epoch_start\n","        print(f\"\\n[Epoch {epoch+1}/{args.epochs}] Time: {elapsed:.1f}s\")\n","        print(f\"  Train - G: {train_metrics['g_loss']:.4f}, D: {train_metrics['d_loss']:.4f}, \"\n","              f\"D_real: {train_metrics['d_real']:.3f}, D_fake: {train_metrics['d_fake']:.3f}, \"\n","              f\"advW: {('%.3e' % (train_metrics['g_loss'] - train_metrics['rec_loss'])) if epoch >= args.warmup_epochs else '0.0e+00'}\")\n","        print(f\"  Val   - Rec: {val_metrics['rec_loss']:.4f}, \"\n","              f\"D_real: {val_metrics['d_real']:.3f}, D_fake: {val_metrics['d_fake']:.3f}\")\n","\n","        # Save best checkpoint if improved\n","        if val_metrics['rec_loss'] < best_val_loss:\n","            best_val_loss = val_metrics['rec_loss']\n","            ckpt_path = ckpt_dir / f\"best_epoch{epoch+1}_val{best_val_loss:.4f}.pth\"\n","            torch.save({\n","                \"epoch\": epoch + 1,\n","                \"generator_state_dict\": generator.state_dict(),\n","                \"discriminator_state_dict\": discriminator.state_dict(),\n","                \"optimizer_g_state_dict\": optimizer_g.state_dict(),\n","                \"optimizer_d_state_dict\": optimizer_d.state_dict(),\n","                \"scheduler_g_state_dict\": scheduler_g.state_dict(),\n","                \"scheduler_d_state_dict\": scheduler_d.state_dict(),\n","                \"best_val_loss\": best_val_loss,\n","                \"history\": history\n","            }, ckpt_path)\n","            print(f\"  Saved best checkpoint to {ckpt_path}\")\n","\n","        # Save regular checkpoint every 10 epochs\n","        # if (epoch + 1) % 10 == 0:\n","        #     ckpt_path = ckpt_dir / f\"checkpoint_epoch{epoch+1}.pth\"\n","        #     torch.save({\n","        #         \"epoch\": epoch + 1,\n","        #         \"generator_state_dict\": generator.state_dict(),\n","        #         \"discriminator_state_dict\": discriminator.state_dict(),\n","        #         \"optimizer_g_state_dict\": optimizer_g.state_dict(),\n","        #         \"optimizer_d_state_dict\": optimizer_d.state_dict(),\n","        #         \"scheduler_g_state_dict\": scheduler_g.state_dict(),\n","        #         \"scheduler_d_state_dict\": scheduler_d.state_dict(),\n","        #         \"best_val_loss\": best_val_loss,\n","        #         \"history\": history\n","        #     }, ckpt_path)\n","\n","        # Plot training curves every 5 epochs\n","        if (epoch + 1) % 10 == 0:\n","            plot_training_curves(history, plot_dir, epoch + 1)\n","        save_epoch_metrics(history, epoch, log_dir,args.log_name)\n","    print(f\"\\n[INFO] Training complete. Best validation loss: {best_val_loss:.6f}\")\n","\n","    # Final test evaluation\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"[INFO] Running final test evaluation...\")\n","    print(\"=\"*60)\n","    test_results = test_and_evaluate()\n","\n","    # Save final plots\n","    plot_training_curves(history, plot_dir, args.epochs, final=True)\n","\n","    # Save training history\n","    history_file = log_dir / \"training_history.json\"\n","    with open(history_file, 'w') as f:\n","        json.dump(history, f, indent=2)\n","    print(f\"\\n[INFO] Training history saved to {history_file}\")\n","\n","\n","def plot_training_curves(history, plot_dir, epoch, final=False):\n","    \"\"\"Create comprehensive training plots for GAN (remains unchanged from original)\"\"\"\n","    plt.style.use('seaborn-v0_8-darkgrid')\n","\n","    # Create figure with subplots\n","    fig = plt.figure(figsize=(20, 15))\n","\n","    # 1. Generator and Discriminator Loss\n","    ax1 = plt.subplot(3, 3, 1)\n","    ax1.plot(history['train_g_loss'], label='Generator Loss', color='blue', linewidth=2)\n","    ax1.plot(history['train_d_loss'], label='Discriminator Loss', color='red', linewidth=2)\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.set_title('Generator vs Discriminator Loss')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # 2. Discriminator Scores on Real/Fake\n","    ax2 = plt.subplot(3, 3, 2)\n","    ax2.plot(history['train_d_real'], label='D(real) - Train', color='green', linewidth=2)\n","    ax2.plot(history['train_d_fake'], label='D(fake) - Train', color='orange', linewidth=2)\n","    ax2.plot(history['val_d_real'], label='D(real) - Val', color='darkgreen', linestyle='--')\n","    ax2.plot(history['val_d_fake'], label='D(fake) - Val', color='darkorange', linestyle='--')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Discriminator Score')\n","    ax2.set_title('Discriminator Scores (Higher=Real, Lower=Fake)')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # 3. Reconstruction Loss\n","    ax3 = plt.subplot(3, 3, 3)\n","    ax3.plot(history['train_rec_loss'], label='Train Rec Loss', color='orange', linewidth=2)\n","    ax3.plot(history['train_adv_loss'], label='Train Adv Loss', color='blue', linewidth=2)\n","    ax3.plot(history['val_rec_loss'], label='Validation Rec Loss', color='purple', linewidth=2)\n","    ax3.set_xlabel('Epoch')\n","    ax3.set_ylabel('Reconstruction Loss')\n","    ax3.set_title('Rec/Adv Loss')\n","    ax3.legend()\n","    ax3.grid(True, alpha=0.3)\n","\n","    # 4. Gradient Penalty (if WGAN-GP)\n","    ax4 = plt.subplot(3, 3, 4)\n","    if history['train_gp'] and any(history['train_gp']):\n","        ax4.plot(history['train_gp'], label='Gradient Penalty', color='brown', linewidth=2)\n","        ax4.set_xlabel('Epoch')\n","        ax4.set_ylabel('GP Value')\n","        ax4.set_title('WGAN-GP Gradient Penalty')\n","        ax4.legend()\n","        ax4.grid(True, alpha=0.3)\n","    else:\n","        ax4.text(0.5, 0.5, 'N/A for Vanilla GAN', ha='center', va='center', transform=ax4.transAxes)\n","        ax4.set_title('Gradient Penalty')\n","\n","    # 5. Learning Rates\n","    ax5 = plt.subplot(3, 3, 5)\n","    ax5.plot(history['lr_g'], label='Generator LR', color='blue', linewidth=2)\n","    ax5.plot(history['lr_d'], label='Discriminator LR', color='red', linewidth=2)\n","    ax5.set_xlabel('Epoch')\n","    ax5.set_ylabel('Learning Rate')\n","    ax5.set_title('Learning Rate Schedule')\n","    ax5.legend()\n","    ax5.grid(True, alpha=0.3)\n","    ax5.set_yscale('log')\n","\n","    # 6. Wasserstein Distance Estimate (D_real - D_fake)\n","    ax6 = plt.subplot(3, 3, 6)\n","    w_dist_train = [r - f for r, f in zip(history['train_d_real'], history['train_d_fake'])]\n","    w_dist_val = [r - f for r, f in zip(history['val_d_real'], history['val_d_fake'])]\n","    ax6.plot(w_dist_train, label='Train', color='blue', linewidth=2)\n","    ax6.plot(w_dist_val, label='Val', color='red', linewidth=2)\n","    ax6.set_xlabel('Epoch')\n","    ax6.set_ylabel('D(real) - D(fake)')\n","    ax6.set_title('Wasserstein Distance Estimate')\n","    ax6.legend()\n","    ax6.grid(True, alpha=0.3)\n","\n","    # 7. Loss Ratio G/D\n","    ax7 = plt.subplot(3, 3, 7)\n","    loss_ratio = [g/d if d != 0 else 0 for g, d in zip(history['train_g_loss'], history['train_d_loss'])]\n","    ax7.plot(loss_ratio, label='G/D Loss Ratio', color='magenta', linewidth=2)\n","    ax7.set_xlabel('Epoch')\n","    ax7.set_ylabel('Ratio')\n","    ax7.set_title('Generator/Discriminator Loss Ratio')\n","    ax7.axhline(y=1, color='k', linestyle='--', alpha=0.5)\n","    ax7.legend()\n","    ax7.grid(True, alpha=0.3)\n","\n","    # 8. Discriminator Accuracy (simplified)\n","    ax8 = plt.subplot(3, 3, 8)\n","    train_acc_real = [1 if score > 0 else 0 for score in history['train_d_real']]\n","    train_acc_fake = [1 if score < 0 else 0 for score in history['train_d_fake']]\n","    train_acc = [(r + f) / 2 for r, f in zip(train_acc_real, train_acc_fake)]\n","\n","    val_acc_real = [1 if score > 0 else 0 for score in history['val_d_real']]\n","    val_acc_fake = [1 if score < 0 else 0 for score in history['val_d_fake']]\n","    val_acc = [(r + f) / 2 for r, f in zip(val_acc_real, val_acc_fake)]\n","\n","    ax8.plot(train_acc, label='Train Accuracy', color='blue', linewidth=2)\n","    ax8.plot(val_acc, label='Val Accuracy', color='red', linewidth=2)\n","    ax8.set_xlabel('Epoch')\n","    ax8.set_ylabel('Accuracy')\n","    ax8.set_title('Discriminator Classification Accuracy')\n","    ax8.set_ylim([0, 1.1])\n","    ax8.legend()\n","    ax8.grid(True, alpha=0.3)\n","\n","    # 9. Loss Components (Log Scale)\n","    ax9 = plt.subplot(3, 3, 9)\n","    ax9.plot(history['train_g_loss'], label='G Loss', color='blue', linewidth=2, alpha=0.7)\n","    ax9.plot(history['train_d_loss'], label='D Loss', color='red', linewidth=2, alpha=0.7)\n","    ax9.plot(history['val_rec_loss'], label='Val Rec Loss', color='green', linewidth=2, alpha=0.7)\n","    ax9.set_xlabel('Epoch')\n","    ax9.set_ylabel('Loss (Log Scale)')\n","    ax9.set_title('All Losses (Log Scale)')\n","    ax9.set_yscale('log')\n","    ax9.legend()\n","    ax9.grid(True, alpha=0.3)\n","\n","    plt.suptitle(f'GAN Training Progress - Epoch {epoch}', fontsize=16)\n","    plt.tight_layout()\n","\n","    # Save plot\n","    if final:\n","        plot_path = plot_dir / \"training_curves_final.png\"\n","    else:\n","        plot_path = plot_dir / f\"training_curves_epoch{epoch}.png\"\n","\n","    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"nEF4j_OTrcYn"},"source":["#Copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIU6aKiYrbuf"},"outputs":[],"source":["import shutil\n","import os\n","\n","src = \"/content/gdrive/MyDrive/ColabData/ReconstructionDataset_Final\"\n","dst = \"/content/data/ReconstructionDataset_Final\"\n","\n","if os.path.exists(dst):\n","    shutil.rmtree(dst)\n","shutil.copytree(src, dst)\n","\n","print(\"Copied files:\", os.listdir(dst))"]},{"cell_type":"markdown","metadata":{"id":"KyLjB69GOYAQ"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJnx-iTVOYc8"},"outputs":[],"source":["print(\"[INFO] Running in IDE debug mode with default settings\")\n","\n","class IDEArgs:\n","    mode = \"train\"\n","    model = \"MultimodalUnetGAN\"\n","    loss = \"mse_loss\"\n","    data_dir = \"/content/data/ReconstructionDataset_Final\"\n","    batch_size = 64\n","    epochs = 300\n","    gpu = 0\n","    ckpt_dir = \"/content/gdrive/MyDrive/Colabdata/checkpoints/\"+model\n","    log_dir = \"/content/gdrive/MyDrive/Colabdata/logs/\"+model\n","    log_name    = model\n","    plot_dir = \"/content/gdrive/MyDrive/Colabdata/plots/\"+model\n","    resume = None\n","\n","    gan_mode = \"wgan-gp\"\n","    d_steps = 5\n","    g_steps = 2\n","    gp_weight = 10\n","    adv_weight = 0.01\n","    lr_g = 2e-4\n","    lr_d = 1e-4\n","    weight_decay = 1e-5\n","    use_amp = True\n","\n","    warmup_epochs = 10\n","    transition_epochs = 10\n","\n","args = IDEArgs()\n","main(args)"]},{"cell_type":"markdown","metadata":{"id":"c78qi0KgVw-h"},"source":["# infer-import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpvflJWZbsI3"},"outputs":[],"source":["!pip install rasterio\n","import sys\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","# Replace with the actual path to the directory containing model2.py\n","model_dir_in_drive = '/content/gdrive/MyDrive/ColabModel/'\n","# Add the directory to the Python path\n","if model_dir_in_drive not in sys.path:\n","    sys.path.append(model_dir_in_drive)\n","    print(f\"Added {model_dir_in_drive} to sys.path\")\n","else:\n","    print(f\"{model_dir_in_drive} already in sys.path\")\n","\n","from MultimodalUnetGAN import UnetGAN\n","import pandas as pd\n","import ast\n","import os\n","import argparse\n","from pathlib import Path\n","import json\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn.functional as F\n","from collections import defaultdict\n","from torch.utils.data import Dataset, DataLoader\n","\n","from scipy.ndimage import binary_erosion\n","from skimage.metrics import structural_similarity as ssim\n","\n","import importlib\n","\n","\n","import rasterio\n","from rasterio.transform import Affine\n","from rasterio.errors import NotGeoreferencedWarning\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)"]},{"cell_type":"markdown","metadata":{"id":"PPNTPftabr4e"},"source":["# infer-config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNySicBHVzho"},"outputs":[],"source":["# -------------------------------------------------------------\n","# 1. Define dataset class (consistent with OptimizedPatchDataset in training script)\n","# -------------------------------------------------------------\n","class OptimizedPatchDataset(Dataset):\n","    \"\"\"Dataset class for loading .pt files with caching,\n","    automatically removing samples whose L30, S1, Planet mask all equal zero.\n","    \"\"\"\n","    def __init__(self, data_dir, cache_size=50, map_location=\"cpu\"):\n","        self.data_dir = Path(data_dir)\n","        all_files = sorted(self.data_dir.glob(\"sample_*.pt\"))\n","        if not all_files:\n","            raise RuntimeError(f\"[OptimizedPatchDataset] No sample_*.pt files found in {self.data_dir}\")\n","\n","        # Filter: only keep samples with at least one non-zero mask\n","        valid_files = []\n","        for p in all_files:\n","            sample = torch.load(p, map_location=map_location)\n","            m0 = sample.get('mask_l30')\n","            m1 = sample.get('mask_s1')\n","            m2 = sample.get('mask_planet')\n","            # Keep if any mask is not all zeros\n","            if not ((m0.sum()==0) and (m1.sum()==0) and (m2.sum()==0)):\n","                valid_files.append(p)\n","        if not valid_files:\n","            raise RuntimeError(\"[OptimizedPatchDataset] All samples have zero masks!\")\n","\n","        self.files = valid_files\n","        self.cache = {}\n","        self.cache_size = cache_size\n","        self.map_location = map_location\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        if idx in self.cache:\n","            return self.cache[idx]\n","        sample = torch.load(self.files[idx], map_location=self.map_location)\n","        # Type adjustment & contiguous\n","        for key, value in sample.items():\n","            if isinstance(value, torch.Tensor):\n","                if value.dtype == torch.float64:\n","                    value = value.float()\n","                sample[key] = value.contiguous()\n","        # Cache\n","        sample[\"__path__\"] = str(self.files[idx])\n","        if len(self.cache) < self.cache_size:\n","            self.cache[idx] = sample\n","        return sample\n","def pad_to_multiple(tensor, mult=16):\n","    \"\"\"\n","    Pad a tensor with shape (..., H, W) so that H and W are both multiples of mult.\n","    Pad zeros on the bottom and right sides.\n","    \"\"\"\n","    *_, H, W = tensor.shape\n","    pad_h = (mult - H % mult) % mult\n","    pad_w = (mult - W % mult) % mult\n","    if pad_h == 0 and pad_w == 0:\n","        return tensor\n","    # Pad format is (pad_left, pad_right, pad_top, pad_bottom)\n","    return F.pad(tensor, (0, pad_w, 0, pad_h))\n","class MultimodalDataset(Dataset):\n","    def __init__(self,\n","                 csv_path,\n","                 root_dir,\n","                 bands_l30=11,\n","                 bands_s1=3,\n","                 bands_planet=7,\n","                 meta_dim=11):\n","        self.df = pd.read_csv(csv_path, dtype=str)\n","        self.root = root_dir\n","        self.bands_l30    = bands_l30\n","        self.bands_s1     = bands_s1\n","        self.bands_planet = bands_planet\n","        self.meta_dim     = meta_dim\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def _parse_list(self, cell):\n","        txt = (cell or '').strip()\n","        if txt.startswith('[') and txt.endswith(']'):\n","            txt = txt[1:-1]\n","        return [x.strip() for x in txt.split(';') if x.strip()]\n","\n","    def _read_raster(self, folder, fname):\n","        path = os.path.join(self.root, folder, fname)\n","        with rasterio.open(path) as src:\n","            arr = src.read().astype(np.float32)\n","        return torch.from_numpy(arr)\n","\n","    def _read_mask(self, folder, fname):\n","        path = os.path.join(self.root, folder, fname)\n","        with rasterio.open(path) as src:\n","            m = src.read(1).astype(np.uint8)\n","        return torch.from_numpy(m[None]).float()\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        date = row['date']\n","\n","        # Parse all lists\n","        s30_files      = self._parse_list(row.get('S30', '[]'))\n","        mask_s30_files = self._parse_list(row.get('S30_mask', '[]'))\n","        l30_files      = self._parse_list(row.get('L30', '[]'))\n","        mask_l30_files = self._parse_list(row.get('L30_mask', '[]'))\n","        s1_files       = self._parse_list(row.get('S1', '[]'))\n","        mask_s1_files  = self._parse_list(row.get('S1_mask', '[]'))\n","        planet_files       = self._parse_list(row.get('Planet', '[]'))\n","        mask_planet_files  = self._parse_list(row.get('Planet_mask', '[]'))\n","\n","        # —— 1) Read S30 GT & mask ——\n","        if s30_files:\n","            s30_img_gt  = self._read_raster('S30',      s30_files[0])\n","        else:\n","            # Fallback: all zeros\n","            # Assume we know H,W first\n","            raise RuntimeError(f\"No S30 for row {idx}\")\n","        if mask_s30_files:\n","            mask_s30 = self._read_mask('S30_mask', mask_s30_files[0])\n","        else:\n","            # Similarly\n","            mask_s30 = torch.zeros(1, s30_img_gt.shape[1], s30_img_gt.shape[2])\n","\n","        # Get H,W for other defaults\n","        _, H, W = s30_img_gt.shape\n","\n","        # —— 2) L30 ——\n","        if l30_files:\n","            l30_img   = self._read_raster('L30',    l30_files[0])\n","            mask_l30  = self._read_mask( 'L30_mask', mask_l30_files[0])\n","        else:\n","            l30_img  = torch.zeros(self.bands_l30, H, W)\n","            mask_l30 = torch.zeros(1,           H, W)\n","\n","        # —— 3) S1 ——\n","        if s1_files:\n","            s1_img  = self._read_raster('S1',     s1_files[0])\n","            mask_s1 = self._read_mask( 'S1_mask', mask_s1_files[0])\n","        else:\n","            s1_img  = torch.zeros(self.bands_s1, H, W)\n","            mask_s1 = torch.zeros(1,           H, W)\n","\n","        # —— 4) Planet ——\n","        if planet_files:\n","            planet_img   = self._read_raster('Planet',    planet_files[0])\n","            mask_planet  = self._read_mask( 'Planet_mask',mask_planet_files[0])\n","        else:\n","            planet_img  = torch.zeros(self.bands_planet, H, W)\n","            mask_planet = torch.zeros(1,                H, W)\n","\n","        # —— 5) Meta all zeros ——\n","        l30_meta    = torch.zeros(self.meta_dim)\n","        s1_meta     = torch.zeros(self.meta_dim)\n","        planet_meta = torch.zeros(self.meta_dim)\n","        s30_fname = s30_files[0]\n","        sample = {\n","           'l30_img':      l30_img,\n","           'mask_l30':     mask_l30,\n","           'l30_meta':     l30_meta,\n","           's1_img':       s1_img,\n","           'mask_s1':      mask_s1,\n","           's1_meta':      s1_meta,\n","           'planet_img':   planet_img,\n","           'mask_planet':  mask_planet,\n","           'planet_meta':  planet_meta,\n","           's30_img_gt':   s30_img_gt,\n","           'mask_s30':     mask_s30,\n","           's30_fname':   s30_fname\n","        }\n","\n","        # —— Uniformly pad all images and masks here ——\n","        for k, v in sample.items():\n","            # Only pad Tensors with shape like (C,H,W) or (1,H,W)\n","            if isinstance(v, torch.Tensor) and v.dim() >= 3:\n","                sample[k] = pad_to_multiple(v, mult=16)\n","\n","        return sample\n","# -------------------------------------------------------------\n","# 2. Define metric functions (same version as used in training)\n","# -------------------------------------------------------------\n","\n","def psnr_masked(img_ref, img_test, valid_mask, data_range=1.0):\n","    \"\"\"Calculate masked PSNR\"\"\"\n","    if img_ref.shape != img_test.shape:\n","        raise ValueError(\"[psnr_masked] Shape mismatch\")\n","    if valid_mask.shape != img_ref.shape[1:]:\n","        raise ValueError(f\"[psnr_masked] Mask shape mismatch\")\n","    I = img_ref.astype(np.float64)\n","    K = img_test.astype(np.float64)\n","    num_valid = np.sum(valid_mask)\n","    if num_valid == 0:\n","        return float(\"nan\")\n","    sq_err = (I - K) ** 2\n","    mask_chw = np.expand_dims(valid_mask, axis=0).repeat(I.shape[0], axis=0)\n","    masked_sq = sq_err[mask_chw > 0]\n","    mse = np.sum(masked_sq) / (num_valid * I.shape[0])\n","    if mse <= 0:\n","        return float(\"inf\")\n","    psnr_val = 10.0 * np.log10((data_range ** 2) / mse)\n","    return float(psnr_val)\n","\n","def ssim_eroded_mask(img_ref, img_test, valid_mask, max_val=1.0, **ssim_kwargs):\n","    \"\"\"Calculate SSIM with eroded mask\"\"\"\n","    if img_ref.shape != img_test.shape:\n","        raise ValueError(\"[ssim_eroded_mask] Shape mismatch\")\n","    C, H, W = img_ref.shape\n","    orig = valid_mask > 0\n","    win_size = ssim_kwargs.pop('win_size', min(3, H, W))\n","    if win_size % 2 == 0:\n","        win_size -= 1\n","    if win_size < 3:\n","        return float(\"nan\")\n","    struct_el = np.ones((win_size, win_size), dtype=bool)\n","    core = binary_erosion(orig, structure=struct_el, border_value=0)\n","    if np.count_nonzero(core) == 0:\n","        return float(\"nan\")\n","    ssim_vals = []\n","    for c in range(C):\n","        ref_c = img_ref[c, :, :]\n","        test_c = img_test[c, :, :]\n","        try:\n","            _, ssim_map = ssim(\n","                ref_c, test_c,\n","                data_range=max_val,\n","                full=True,\n","                **ssim_kwargs\n","            )\n","            ssim_vals.append(np.mean(ssim_map[core]))\n","        except Exception:\n","            ssim_vals.append(float(\"nan\"))\n","    return float(np.nanmean(ssim_vals))\n","\n","def sam_masked(img_ref, img_test, valid_mask):\n","    \"\"\"Calculate masked SAM (Spectral Angle Mapper)\"\"\"\n","    if img_ref.shape != img_test.shape:\n","        raise ValueError(\"[sam_masked] Shape mismatch\")\n","    C, H, W = img_ref.shape\n","    I = img_ref.astype(np.float64)\n","    K = img_test.astype(np.float64)\n","    mask_bool = valid_mask > 0\n","    if not np.any(mask_bool):\n","        return float(\"nan\")\n","    I_flat = I[:, mask_bool]\n","    K_flat = K[:, mask_bool]\n","    dot = np.sum(I_flat * K_flat, axis=0)\n","    norm_I = np.linalg.norm(I_flat, axis=0)\n","    norm_K = np.linalg.norm(K_flat, axis=0)\n","    denom = norm_I * norm_K\n","    valid_idx = denom > 0\n","    if not np.any(valid_idx):\n","        return float(\"nan\")\n","    cos_theta = dot[valid_idx] / denom[valid_idx]\n","    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n","    angles = np.arccos(cos_theta)\n","    sam_deg = np.degrees(angles)\n","    return float(np.mean(sam_deg))\n","\n","# -------------------------------------------------------------\n","# 3. Dynamically load ModelClass\n","# -------------------------------------------------------------\n","# Assume pred is a NumPy array with shape (12, H, W), dtype float32\n","# Similarly, gt is the ground truth array with shape (12, H, W)\n","def save_multiband_tif_rasterio(array_3d, output_path):\n","    \"\"\"\n","    Use rasterio to save array_3d with shape (C, H, W) as a 12-band GeoTIFF (without geographic coordinate information)\n","    \"\"\"\n","    C, H, W = array_3d.shape\n","    assert C <= 2**16, \"Number of bands should not be too large!\"\n","    # No geographic reference, Affine.identity is equivalent to pixel-coordinate identity matrix\n","    transform = Affine.identity()\n","\n","    # Open a new write handle\n","    with rasterio.open(\n","        output_path,\n","        'w',\n","        driver='GTiff',\n","        height=H,\n","        width=W,\n","        count=C,            # Number of bands\n","        dtype=array_3d.dtype,\n","        crs=None,           # No coordinate system\n","        transform=transform\n","    ) as dst:\n","        # Write band by band\n","        for band_idx in range(C):\n","            dst.write(array_3d[band_idx], band_idx + 1)\n","def GenerateMask(x,dim=1):\n","    mask = (x != 0).float().sum(dim=dim)\n","    mask = mask.unsqueeze(1)\n","    return mask"]},{"cell_type":"markdown","metadata":{"id":"FCGqBIpMb5ol"},"source":["#infer-main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VRzzWJub5Du"},"outputs":[],"source":["# -------------------------------------------------------------\n","# 4. Inference main function\n","# -------------------------------------------------------------\n","def main(args):\n","    # Select device\n","    device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n","    print(f\"[INFO] Using device: {device}\")\n","\n","    # Create output directories\n","    output_dir = Path(args.output_dir)\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","    vis_dir = output_dir / \"visualizations\"\n","    vis_dir.mkdir(parents=True, exist_ok=True)\n","    arrays_dir = output_dir / \"arrays\"\n","    arrays_dir.mkdir(parents=True, exist_ok=True)\n","\n","    # ------------------------------------------------------------------\n","    # 4.1 Load model\n","    # ------------------------------------------------------------------\n","    # model = UnetGAN(use_meta=True,use_selfattention=True).to(device)#False,True\n","    model = UnetGAN(use_meta=True, use_selfattention=True,\n","                    use_spatial_attention=True).to(device)#True,False\n","    # Check if has generator attribute\n","    if not hasattr(model, \"generator\"):\n","        raise AttributeError(f\"[ERROR] Model '{args.model}' does not have attribute 'generator'\")\n","    generator = model.generator\n","\n","    # Load checkpoint\n","    if not os.path.isfile(args.ckpt_path):\n","        raise FileNotFoundError(f\"[ERROR] Checkpoint not found: {args.ckpt_path}\")\n","    ckpt = torch.load(args.ckpt_path, map_location=device,weights_only=False)\n","    if \"generator_state_dict\" in ckpt:\n","        generator.load_state_dict(ckpt[\"generator_state_dict\"])\n","    else:\n","        generator.load_state_dict(ckpt)\n","    generator.eval()\n","    print(f\"[INFO] Loaded checkpoint from {args.ckpt_path}\")\n","\n","    # ------------------------------------------------------------------\n","    # 4.2 Prepare test dataset DataLoader\n","    # ------------------------------------------------------------------\n","    test_dir = Path(args.data_dir) / \"test\"\n","    if not test_dir.exists():\n","        raise RuntimeError(f\"[ERROR] Test directory '{test_dir}' does not exist\")\n","    test_dataset = OptimizedPatchDataset(test_dir, cache_size=500, map_location=\"cpu\")\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        num_workers=args.num_workers,\n","        pin_memory=True\n","    )\n","\n","    # merged_base =  Path(args.data_dir)\n","    # # r'C:/Users/TongYu/Desktop/processed_merged'\n","    # csv_path    = os.path.join(merged_base, 'processed_image_info_merged.csv')\n","\n","    # test_dataset = MultimodalDataset(\n","    #     csv_path=csv_path,\n","    #     root_dir=merged_base,\n","    #     bands_l30=11,\n","    #     bands_s1=3,\n","    #     bands_planet=7,\n","    #     meta_dim=11\n","    # )\n","    # test_loader = DataLoader(\n","    #     test_dataset,\n","    #     batch_size=args.batch_size,\n","    #     shuffle=False,\n","    #     num_workers=args.num_workers,\n","    #     pin_memory=True)\n","\n","\n","    # ------------------------------------------------------------------\n","    # 4.3 Inference loop: run inference on all samples in test_loader and calculate metrics\n","    # ------------------------------------------------------------------\n","    results = []\n","    total_mse, total_rmse, total_psnr, total_ssim, total_sam = [], [], [], [], []\n","    metrics_by_combo = defaultdict(list)\n","\n","    with torch.no_grad():\n","        pbar = tqdm(test_loader, desc=\"[Inference]\")\n","        for batch_idx, batch in enumerate(pbar):\n","            # Move data to device\n","            l30_img = batch[\"l30_img\"].to(device, non_blocking=True)\n","            # mask_l30 = batch[\"mask_l30\"].to(device, non_blocking=True)\n","            l30_meta = batch[\"l30_meta\"].to(device, non_blocking=True)\n","            s1_img   = batch[\"s1_img\"].to(device, non_blocking=True)\n","            # mask_s1  = batch[\"mask_s1\"].to(device, non_blocking=True)\n","            s1_meta  = batch[\"s1_meta\"].to(device, non_blocking=True)\n","            planet_img = batch[\"planet_img\"].to(device, non_blocking=True)\n","            # mask_planet = batch[\"mask_planet\"].to(device, non_blocking=True)\n","            planet_meta = batch[\"planet_meta\"].to(device, non_blocking=True)\n","            s30_gt   = batch[\"s30_img_gt\"].to(device, non_blocking=True)\n","            mask_s30 = batch[\"mask_s30\"].to(device, non_blocking=True)\n","\n","            # Forward inference\n","            fake_s30 = generator(\n","                l30_img, l30_meta,\n","                s1_img, s1_meta,\n","                planet_img, planet_meta\n","            )\n","            #********************************\n","            # input_union = (mask_l30 > 0) | (mask_s1 > 0) | (mask_planet > 0)\n","            # # 2) Intersect with S30 mask\n","            # joint_mask = input_union & (mask_s30 > 0)\n","\n","            # # 3) Expand to (B, C_out, H, W) and convert to float\n","            # mask_ext = joint_mask.float().expand(-1, fake_s30.size(1), -1, -1)\n","\n","            # # 4) Crop output with intersection mask\n","            # fake_s30 = fake_s30 * mask_ext\n","            # s30_gt = s30_gt * mask_ext\n","            #********************************\n","            mask_ext = mask_s30.expand(-1, fake_s30.size(1), -1, -1)\n","            fake_s30 = fake_s30 * mask_ext\n","\n","            # Convert to numpy array for metric calculation and saving\n","            fake_np = fake_s30.detach().cpu().numpy()  # shape (B, C=12, H, W)\n","            gt_np   = s30_gt.detach().cpu().numpy()    # shape (B, C=12, H, W)\n","            mask_np = mask_s30.detach().cpu().numpy().squeeze(1)  # (B, H, W)\n","\n","            mask_l30_np=GenerateMask(l30_img,dim=1).squeeze(1)\n","            mask_s1_np=GenerateMask(s1_img,dim=1).squeeze(1)\n","            mask_planet_np=GenerateMask(planet_img,dim=1).squeeze(1)\n","\n","            # mask_l30_np    = mask_l30.detach().cpu().numpy().squeeze(1)\n","            # mask_s1_np     = mask_s1.detach().cpu().numpy().squeeze(1)\n","            # mask_planet_np = mask_planet.detach().cpu().numpy().squeeze(1)\n","\n","            B = fake_np.shape[0]\n","            for i in range(B):\n","                pred = fake_np[i]  # (12, H, W)\n","                gt   = gt_np[i]    # (12, H, W)\n","                mask = mask_np[i]  # (H, W)\n","\n","                # Per-pixel MSE / RMSE\n","                sq_err = (pred - gt) ** 2\n","                num_valid = np.sum(mask) * pred.shape[0]\n","                if num_valid > 0:\n","                    mse_val = np.sum(sq_err * mask[np.newaxis, ...]) / num_valid\n","                else:\n","                    mse_val = float(\"nan\")\n","                rmse_val = np.sqrt(mse_val) if not np.isnan(mse_val) else float(\"nan\")\n","\n","                # PSNR / SSIM / SAM\n","                psnr_val = psnr_masked(gt, pred, mask, data_range=1.0)\n","                ssim_val = ssim_eroded_mask(gt, pred, mask, max_val=1.0)\n","                sam_val  = sam_masked(gt, pred, mask)\n","                # Group metrics by input combination\n","                combo = []\n","                if mask_l30_np[i].any():    combo.append(\"L30\")\n","                if mask_s1_np[i].any():     combo.append(\"S1\")\n","                if mask_planet_np[i].any(): combo.append(\"Planet\")\n","                # combo_key = \"+\".join(combo) if combo else \"None\"\n","                if combo:\n","                    combo_key = \"+\".join(combo)\n","                else:\n","                    combo_key = \"None\"\n","                metrics_by_combo[combo_key].append({\"mse\": mse_val, \"rmse\": rmse_val, \"psnr\": psnr_val, \"ssim\": ssim_val, \"sam\": sam_val})\n","\n","                total_mse.append(mse_val)\n","                total_rmse.append(rmse_val)\n","                total_psnr.append(psnr_val)\n","                total_ssim.append(ssim_val)\n","                total_sam.append(sam_val)\n","\n","                # Construct sample name: use original .pt filename (without extension)\n","                full_path = batch[\"__path__\"][i]\n","                sample_name = Path(full_path).stem\n","\n","                # # batch['s30_fname'][i] example: 'F1_5_8_2022_S30.tif'\n","                # stem = Path(batch['s30_fname'][i]).stem\n","                # # Remove '_S30' suffix to get 'F1_5_8_2022'\n","                # if stem.endswith('_S30'):\n","                #     sample_name = stem[:-len('_S30')]\n","                # else:\n","                #     sample_name = stem\n","\n","                # Save complete 12-band array as TIFF\n","                pred_save_path = arrays_dir / f\"{sample_name}_pred.tif\"\n","                gt_save_path   = arrays_dir / f\"{sample_name}_gt.tif\"\n","                save_multiband_tif_rasterio(pred, pred_save_path)\n","                save_multiband_tif_rasterio(gt,   gt_save_path)\n","\n","                # Save metric information\n","                results.append({\n","                    \"sample\": sample_name,\n","                    \"mse\": float(mse_val),\n","                    \"rmse\": float(rmse_val),\n","                    \"psnr\": float(psnr_val),\n","                    \"ssim\": float(ssim_val),\n","                    \"sam\": float(sam_val),\n","                })\n","\n","                # Visualize and save: RGB bands use 2,1,0\n","                if pred.shape[0] >= 3:\n","                    pred_rgb = np.clip(pred[[2,1,0]].transpose(1, 2, 0), 0, 1)\n","                    gt_rgb   = np.clip(gt[[2,1,0]].transpose(1, 2, 0), 0, 1)\n","                else:\n","                    pred_rgb = np.repeat(pred[0:1].transpose(1, 2, 0), 3, axis=2)\n","                    gt_rgb   = np.repeat(gt[0:1].transpose(1, 2, 0), 3, axis=2)\n","                diff = np.abs(pred_rgb - gt_rgb)\n","\n","                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","                axes[0].imshow(gt_rgb)\n","                axes[0].set_title(\"Ground Truth (bands 2,1,0)\")\n","                axes[0].axis(\"off\")\n","                axes[1].imshow(pred_rgb)\n","                axes[1].set_title(f\"Prediction (PSNR: {psnr_val:.2f} dB)\")\n","                axes[1].axis(\"off\")\n","                axes[2].imshow(diff, cmap='hot')\n","                axes[2].set_title(\"Absolute Difference\")\n","                axes[2].axis(\"off\")\n","                plt.tight_layout()\n","\n","                # Construct visualization save path\n","                vis_save_path = vis_dir / f\"{sample_name}.png\"\n","                plt.savefig(vis_save_path, dpi=200, bbox_inches='tight')\n","                plt.close(fig)\n","\n","            # Update progress bar\n","            pbar.set_postfix({\n","                \"MSE\": f\"{np.nanmean(total_mse):.6f}\",\n","                \"PSNR\": f\"{np.nanmean(total_psnr):.2f}\",\n","                \"SSIM\": f\"{np.nanmean(total_ssim):.4f}\"\n","            })\n","\n","    # ------------------------------------------------------------------\n","    # 4.4 Aggregate and save metrics\n","    # ------------------------------------------------------------------\n","    summary = {\n","        \"num_samples\": len(total_mse),\n","        \"mse_mean\": float(np.nanmean(total_mse)),\n","        \"mse_std\":  float(np.nanstd(total_mse)),\n","        \"rmse_mean\": float(np.nanmean(total_rmse)),\n","        \"rmse_std\":  float(np.nanstd(total_rmse)),\n","        \"psnr_mean\": float(np.nanmean(total_psnr)),\n","        \"psnr_std\":  float(np.nanstd(total_psnr)),\n","        \"ssim_mean\": float(np.nanmean(total_ssim)),\n","        \"ssim_std\":  float(np.nanstd(total_ssim)),\n","        \"sam_mean\":  float(np.nanmean(total_sam)),\n","        \"sam_std\":   float(np.nanstd(total_sam)),\n","    }\n","\n","    # Save all sample metrics to JSON\n","    results_file = output_dir / \"inference_results.json\"\n","    with open(results_file, \"w\") as f:\n","        json.dump({\n","            \"summary\": summary,\n","            \"details\": results\n","        }, f, indent=2)\n","        # Performance summary by input combination\n","        combo_summaries = {}\n","        for combo_key, records in metrics_by_combo.items():\n","            arr = np.array([[r[\"psnr\"], r[\"ssim\"], r[\"sam\"], r[\"mse\"], r[\"rmse\"]] for r in records])\n","            combo_summaries[combo_key] = {\n","                \"count\": len(records),\n","                \"psnr_mean\": float(np.nanmean(arr[:,0])), \"psnr_std\": float(np.nanstd(arr[:,0])),\n","                \"ssim_mean\": float(np.nanmean(arr[:,1])), \"ssim_std\": float(np.nanstd(arr[:,1])),\n","                \"sam_mean\": float(np.nanmean(arr[:,2])),   \"sam_std\": float(np.nanstd(arr[:,2])),\n","                \"mse_mean\": float(np.nanmean(arr[:,3])),   \"mse_std\": float(np.nanstd(arr[:,3])),\n","                \"rmse_mean\": float(np.nanmean(arr[:,4])),  \"rmse_std\": float(np.nanstd(arr[:,4])),\n","            }\n","        full_summary = {\"summary\": summary, \"by_input_combo\": combo_summaries}\n","        with open(output_dir/\"inference_summary_by_combo.json\", \"w\") as f2:\n","            json.dump(full_summary, f2, indent=2)\n","        print(\"\\n=== Performance by Input Combination ===\")\n","        for combo, stats in combo_summaries.items():\n","            print(f\"{combo}: {stats['count']} samples — PSNR {stats['psnr_mean']:.2f}±{stats['psnr_std']:.2f}, SSIM {stats['ssim_mean']:.3f}±{stats['ssim_std']:.3f}, SAM {stats['sam_mean']:.2f}±{stats['sam_std']:.2f}\")\n","    print(f\"\\n[INFO] Inference completed. Results saved to {results_file}\")\n","    print(f\"       Full 12-band TIFFs saved to {arrays_dir}\")\n","    print(f\"       Visualizations saved to {vis_dir}\")\n","\n","    # Print summary information\n","    print(\"\\nInference Summary:\")\n","    for k, v in summary.items():\n","        if isinstance(v, float):\n","            print(f\"  {k}: {v:.6f}\")\n","        else:\n","            print(f\"  {k}: {v}\")\n","\n","# -------------------------------------------------------------\n","# 5. Command line entry & IDE debugging\n","# -------------------------------------------------------------\n","def parse_args():\n","    parser = argparse.ArgumentParser(\n","        description=\"Inference script for trained GAN generator (save 12-band TIFF)\"\n","    )\n","    parser.add_argument(\"--model\",      type=str, required=True,\n","                        help=\"Model name (MODEL_CLASS must be defined in Models/{model}.py)\")\n","    parser.add_argument(\"--ckpt-path\",  type=str, required=True,\n","                        help=\"Generator checkpoint path (can be entire model or generator_state_dict)\")\n","    parser.add_argument(\"--data-dir\",   type=str, required=True,\n","                        help=\"Data root directory, should contain 'test' subdirectory (consistent with training script)\")\n","    parser.add_argument(\"--output-dir\", type=str, default=\"inference_results\",\n","                        help=\"Inference results output directory (contains TIFF and visualizations)\")\n","    parser.add_argument(\"--batch-size\", type=int, default=16)\n","    parser.add_argument(\"--num-workers\", type=int, default=4)\n","    parser.add_argument(\"--device\",     type=str, default=\"cuda:0\",\n","                        help=\"Device to run inference (e.g., 'cuda:0' or 'cpu')\")\n","    return parser.parse_args()"]},{"cell_type":"markdown","metadata":{"id":"KFRKNiHBcMbF"},"source":["#infer-run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DF73s9uVcMFU"},"outputs":[],"source":["print(\"[INFO] Running in IDE debug mode with default settings\")\n","\n","class IDEArgs:\n","    model = \"MultimodalUnetGAN\"\n","    ckpt_path = \"/content/gdrive/MyDrive/Colabdata/checkpoints/MultimodalUnetGAN_adap_all/best_epoch****.pth\"\n","    data_dir = \"/content/data/ReconstructionDataset_Final\"\n","    output_dir = \"/content/gdrive/MyDrive/Colabdata/inference_results/\"+model\n","    batch_size = 64\n","    num_workers = 4\n","    device = \"cuda:0\"\n","\n","args = IDEArgs()\n","main(args)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"toc_visible":true,"mount_file_id":"1tFk_ksbMSWCYzekDDwWotDvoRls9FKOu","authorship_tag":"ABX9TyNKyR/iznapkXAHTTaez5gp"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":0}